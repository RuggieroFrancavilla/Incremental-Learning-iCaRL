{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetuning_definitivo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"01mnXmFnUFdV"},"source":["**Import libraries**\n"]},{"cell_type":"code","metadata":{"id":"crURUb9gURME"},"source":["import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset, DataLoader\n","from torch.backends import cudnn\n","\n","\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR100\n","from torchvision.models import resnet\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import seaborn as sns\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Load resnet_cifar.py\n","import os\n","if not os.path.exists(\"./resnet_cifar.py\"):\n","    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=14ugdr3UoIWHmRCRS9KrJiQmCRK9WvCVj' -O resnet_cifar.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"US3YGeI1UT4U"},"source":["**Set Arguments**\n"]},{"cell_type":"code","metadata":{"id":"Rn1Q6EXlUbQS"},"source":["DEVICE = 'cuda'\n","\n","BATCH_SIZE = 128\n","\n","K = 2000\n","NUM_EPOCHS = 70\n","\n","LR = 0.2\n","MOMENTUM = 0.9\n","STEP_SIZE = [49,63]\n","GAMMA = 0.2\n","WEIGHT_DECAY = 1e-5\n","LOG_FREQUENCY = 10\n","\n","# Random seeds\n","np.random.seed(653)\n","torch.manual_seed(653)\n","torch.cuda.manual_seed(653)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHQdgNlTwRSE"},"source":["**Some utility functions**"]},{"cell_type":"code","metadata":{"id":"-W1-YQnvw6Fj"},"source":["def subset_indices(dataset, classes):\r\n","    # Returns the indices for the creation of a subset of a dataset containing only the images of the specified classes\r\n","    indices = []\r\n","    for img_index, (_, img_label) in enumerate(dataset):\r\n","        if img_label in classes:\r\n","            indices.append(img_index)     # append the index of those images belonging to class c\r\n","    return indices\r\n","\r\n","def show_heatmap_CM(labels, predictions):\r\n","    \"\"\"\r\n","    Plot the confusion matrix as a heat map, given ground truth labels and the model predictions\r\n","    \r\n","    Params:\r\n","        labels: ground truth labels\r\n","        predictions: model predictions of the labels\r\n","\r\n","    Return:\r\n","        Show the heatmap\r\n","        x axis: predicted class\r\n","        y axis: true class\r\n","    \"\"\"\r\n","    fig, ax = plt.subplots(figsize=(9,9))\r\n","\r\n","    # Build confusion matrix (as a 100x100 numpy array)\r\n","    cm = confusion_matrix(labels, predictions, labels=seen_classes)\r\n","\r\n","    # Convert the confusion matrix to a 100x100 pandas dataframe (dimensions len(labels) x len(predictions) )\r\n","    df_cm = pd.DataFrame(cm, seen_classes, seen_classes)\r\n","    df_cm.columns = np.arange(100)+20    # for plotting reasons\r\n","    df_cm.index = np.arange(100)+20    # for plotting reasons\r\n","\r\n","    # Visualize the confusion matrix as a heat map\r\n","    ax = sns.heatmap(df_cm, xticklabels=20, yticklabels=20, cbar=False, square=False, cmap='OrRd')\r\n","    sns.set(font_scale = 2)\r\n","    ax.set(xlabel='Predicted class', ylabel='True class')\r\n","    pos, textvals = plt.xticks()\r\n","    plt.xticks(np.array(pos)+20, textvals, va=\"center\")\r\n","    pos, textvals = plt.yticks()\r\n","    plt.yticks(np.array(pos)+20, textvals, va=\"center\")\r\n","    ax.tick_params(axis='x', pad=15)\r\n","\r\n","    plt.show()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-wkPG3vuUiBK"},"source":["**Define Data Processing**"]},{"cell_type":"code","metadata":{"id":"omg4hzrgUlfR"},"source":["# Define transforms for training phase\n","train_transform = transforms.Compose([transforms.RandomCrop(32, padding=2),\n","                                      transforms.RandomHorizontalFlip(p=0.5),\n","                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n","                                      transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n","                                                            std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404]) # Normalizes tensor with mean and standard deviation\n","])\n","\n","# Define transforms for the evaluation phase\n","eval_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[0.5088964127604166, 0.48739301317401956, 0.44194221124387256],\n","                                                          std=[0.2682515741720801, 0.2573637364478126, 0.2770957707973042])                                    \n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZYBrIvsUl2M"},"source":["**Prepare Dataset**"]},{"cell_type":"code","metadata":{"id":"u5DSZrgzUqFP"},"source":["# Load CIFAR100 training and test datasets \n","cifar100_training = CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n","cifar100_test = CIFAR100(root='./data', train=False, transform=eval_transform)\n","\n","# Check dataset sizes\n","print(f'Training set size: {len(cifar100_training)}')\n","print(f'Test set size: {len(cifar100_test)}')\n","\n","\n","# Create an array with a random permutation of the 100 classes, with 10 rows of 10 classes each\n","classes = np.random.permutation(np.arange(100)).reshape((10,10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ejm8r9xUuDn"},"source":["**Prepare Network**"]},{"cell_type":"code","metadata":{"id":"ynBoTE5wUzil"},"source":["from resnet_cifar import resnet32\n","\n","net = resnet32(num_classes = 100)   # Loading ResNet32 model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5DlyxgSUz6Q"},"source":["**Define loss function**"]},{"cell_type":"code","metadata":{"id":"omEZE_sQU4Cn"},"source":["# Classification loss\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73_WXopXU4PZ"},"source":["**Training and testing**"]},{"cell_type":"code","metadata":{"id":"poq9MmpnU7Pg"},"source":["# By default, everything is loaded to cpu\n","net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","cudnn.benchmark # Calling this optimizes runtime\n","\n","test_acc_history = []  # this list shall contain 10 values (one for each seen class)\n","\n","global_step_counter = 0\n","task_step_counter = 1 # Incremented by one every time one set of 10 classes is seen\n","\n","seen_classes_counter = 0\n","seen_classes = []\n","\n","for current_classes in classes:     # 10 cycles (over the 10 sets of classes)\n","\n","    # Create a dataloader for the new 10 classes to train on\n","    training_subset_idx = subset_indices(cifar100_training, current_classes)\n","    training_subset = Subset(cifar100_training, training_subset_idx)\n","    training_dataloader = DataLoader(training_subset, shuffle=True, num_workers=4, batch_size=BATCH_SIZE, drop_last=True)\n","    \n","    # Initialize the optimizer and the scheduler\n","    parameters_to_optimize = net.parameters()\n","    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, STEP_SIZE, gamma=GAMMA)\n","    \n","\n","\n","    # TRAINING PHASE\n","    # train on the next set of 10 unseen classes\n","\n","\n","    \n","    # 10 previously unseen classes are now being seen\n","    seen_classes_counter += 1\n","    seen_classes += current_classes.tolist()\n","\n","    epoch_step_counter = 0\n","\n","    for epoch in range(NUM_EPOCHS):\n","        print(f'Starting epoch {epoch+1}/{NUM_EPOCHS}, LR = {scheduler.get_last_lr()}')\n","        t = time.time()\n","\n","        net.train(True)\n","        \n","        total_training_corrects = 0\n","        running_loss = 0\n","    \n","        for images, labels in training_dataloader:\n","\n","            # Bring data over the device of choice\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            optimizer.zero_grad() # Zero-ing the gradients\n","\n","            # Forward pass to the network\n","            outputs = net(images)\n","            \n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update Corrects\n","            total_training_corrects += torch.sum(preds == labels.data).data.item()\n","\n","            # Compute loss based on output and ground truth\n","            loss = criterion(outputs, labels)\n","\n","            # Log loss\n","            if epoch_step_counter % LOG_FREQUENCY == 0:\n","                print(f'Step: {epoch_step_counter}, training loss: {loss.item()}')\n","            \n","            # Compute gradients for each layer and update weights\n","            loss.backward()  # backward pass: computes gradients\n","            optimizer.step() # update weights based on accumulated gradients\n","\n","            # Update counters\n","            epoch_step_counter += 1\n","            global_step_counter += 1\n","\n","\n","        current_classes_training_accuracy = total_training_corrects / (float(len(training_dataloader)) * BATCH_SIZE)\n","        print(f'------ Epoch {epoch+1}/{NUM_EPOCHS} of the training on the {task_step_counter}Â° set of classes has ended.\\n------ Training accuracy (only on the current 10 classes): {current_classes_training_accuracy}\\n------ Elapsed time for this epoch: {time.time() - t}')\n","\n","        # Step the scheduler\n","        scheduler.step()\n","\n","    task_step_counter += 1\n","\n","\n","\n","    # TEST PHASE\n","    # evaluate the network on (all) the test images of the classes seen so far\n","\n","\n","\n","    # Create a dataloader for the test images of all the classes seen so far\n","    test_subset_idx = subset_indices(cifar100_test, seen_classes)\n","    test_subset = Subset(cifar100_test, test_subset_idx)\n","    test_dataloader = DataLoader(test_subset, shuffle=False, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    net.train(False)    # Set Network to evaluation mode\n","\n","    all_test_labels = torch.LongTensor([]).to(DEVICE)\n","    all_test_preds = torch.LongTensor([]).to(DEVICE)\n","\n","    total_test_corrects = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_dataloader:\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            # Forward Pass\n","            outputs = net(images)\n","\n","            # Get predictions (for reporting purposes)\n","            _, preds = torch.max(outputs.data, 1)\n","            current_batch_corrects = torch.sum(preds == labels.data).data.item()\n","\n","            # Update the running amount of correct predictions (for plotting purposes)\n","            total_test_corrects += current_batch_corrects\n","\n","            # Store the current batch labels and preds; needed later for plotting the heatmap\n","            all_test_labels = torch.cat((all_test_labels, labels), 0)\n","            all_test_preds = torch.cat((all_test_preds, preds), 0)\n","    \n","        test_accuracy = total_test_corrects / float(len(test_subset))\n","        test_acc_history.append(test_accuracy)\n","\n","        print(f'---------- Training ended on the {int(seen_classes_counter / 10)}Â° set of classes\\n---------- Test accuracy: {test_accuracy}')\n","\n","\n","torch.save(net, './SavedNet') # SavedNet on drive folder\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZsoDz2CegGc"},"source":["# Print the ten test accuracies obtained\r\n","print(test_acc_history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0xjbReTSV2s0"},"source":["**Heat map Confusion Matrix**"]},{"cell_type":"code","metadata":{"id":"xUD5NbMvnSMo"},"source":["# Show the confusion matrix for the test set as a heatmap\r\n","show_heatmap_CM(all_test_labels.cpu(), all_test_preds.cpu())"],"execution_count":null,"outputs":[]}]}