{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"iCaRL + TenCrop.ipynb","provenance":[{"file_id":"1S9l0AeljfsQsCkSbVn9RsSkISD9VlLLV","timestamp":1591951315087}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"42be7813d7a0496ea0a5366595e8b76a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d2da13e6f464baeb2923a0f900c364c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_49b54dd099384a3fb07d6c7e453d0bc2","IPY_MODEL_7431a30bb47b47738c735f2da8d358c6"]}},"7d2da13e6f464baeb2923a0f900c364c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49b54dd099384a3fb07d6c7e453d0bc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_71ad3360a1cf403786ab7d3bd3b69b92","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_965a443a8989415b8ae857d5c842fa4c"}},"7431a30bb47b47738c735f2da8d358c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf618557b23d44aa9c27d5b54f483418","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169009152/? [00:20&lt;00:00, 102672704.55it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c408b8349d004542b572dd4261b698ac"}},"71ad3360a1cf403786ab7d3bd3b69b92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"965a443a8989415b8ae857d5c842fa4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf618557b23d44aa9c27d5b54f483418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c408b8349d004542b572dd4261b698ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"01mnXmFnUFdV"},"source":["**Import libraries**\n"]},{"cell_type":"code","metadata":{"id":"crURUb9gURME","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607984300080,"user_tz":-60,"elapsed":6364,"user":{"displayName":"Tommaso Monopoli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghnx0g62sTlKYYaGZJdG5FNjVxq7rbrSNzd36V42A=s64","userId":"05588580840073678935"}},"outputId":"7d416130-dcfc-47fe-8bfd-03f6b7673439"},"source":["import time\n","from copy import deepcopy\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset, DataLoader\n","from torch.backends import cudnn\n","from torch.nn.functional import one_hot\n","\n","\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR100\n","from torchvision.models import resnet\n","\n","import numpy as np\n","from numpy.linalg import norm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import seaborn as sns\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Load resnet_cifar.py\n","import os\n","if not os.path.exists(\"./resnet_cifar.py\"):\n","    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=14ugdr3UoIWHmRCRS9KrJiQmCRK9WvCVj' -O resnet_cifar.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-12-14 22:18:18--  https://docs.google.com/uc?export=download&id=14ugdr3UoIWHmRCRS9KrJiQmCRK9WvCVj\n","Resolving docs.google.com (docs.google.com)... 172.217.164.142, 2607:f8b0:4004:814::200e\n","Connecting to docs.google.com (docs.google.com)|172.217.164.142|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-10-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7i93udod75itm3il2gbejdslrvcnu2t8/1607984250000/05588580840073678935/*/14ugdr3UoIWHmRCRS9KrJiQmCRK9WvCVj?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2020-12-14 22:18:19--  https://doc-10-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7i93udod75itm3il2gbejdslrvcnu2t8/1607984250000/05588580840073678935/*/14ugdr3UoIWHmRCRS9KrJiQmCRK9WvCVj?e=download\n","Resolving doc-10-1g-docs.googleusercontent.com (doc-10-1g-docs.googleusercontent.com)... 172.217.9.193, 2607:f8b0:4004:806::2001\n","Connecting to doc-10-1g-docs.googleusercontent.com (doc-10-1g-docs.googleusercontent.com)|172.217.9.193|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4584 (4.5K) [text/plain]\n","Saving to: ‘resnet_cifar.py’\n","\n","resnet_cifar.py     100%[===================>]   4.48K  --.-KB/s    in 0s      \n","\n","2020-12-14 22:18:19 (73.5 MB/s) - ‘resnet_cifar.py’ saved [4584/4584]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"US3YGeI1UT4U"},"source":["**Set Arguments**\n"]},{"cell_type":"code","metadata":{"id":"Rn1Q6EXlUbQS"},"source":["DEVICE = 'cuda'\n","\n","BATCH_SIZE = 128\n","\n","K = 2000\n","NUM_EPOCHS = 70  # 70\n","\n","LR = 2.0\n","MOMENTUM = 0.9\n","STEP_SIZE = [49,63]\n","GAMMA = 0.2\n","WEIGHT_DECAY = 1e-5\n","LOG_FREQUENCY = 10\n","\n","# Random seeds\n","np.random.seed(653)\n","torch.manual_seed(653)\n","torch.cuda.manual_seed(653)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SIttza66zgeP"},"source":["**Some utility functions**"]},{"cell_type":"code","metadata":{"id":"fJ01T0SdzfpZ"},"source":["def compute_means_of_exemplars(net, dataset, exemplars_idx, n):\n","    \"\"\"\n","    Compute the L2-normalized mean-of-exemplars (AKA average feature vectors) for the first n classes seen\n","    Returns:\n","        a (seen_classes_counter, 64) numpy array whose rows are the mean-of-exemplars of the seen_classes_counter classes seen so far, computed using the current exemplars\n","    \"\"\"\n","    if n == 0:    # if seen_classes_counter = 0 then return an empty array\n","        return np.array([]).reshape((0,64))\n","    \n","    class_means = []    # this will contain seen_classes_counter lists; i-th list will contain the L2-normalized mean-of-exemplars for the i-th seen class\n","\n","    for i in range(n):   # for each i-th seen class\n","\n","        # Retrieve the exemplars of the i-th seen class\n","        list_exemplars = [dataset[exemplar_idx][0] for exemplar_idx in exemplars_idx[i]]    # a list of tensors, containing the m exemplars of the i-th seen class\n","        exemplars_images = torch.stack(list_exemplars).cuda()     # a tensor containing the m exemplars of the i-th seen class    \n","\n","        # Compute the average feature vector of the i-th seen class\n","        features = net.get_features(exemplars_images).cpu().data.numpy()    # feature vectors of the m exemplars of the i-th seen class (m, 64)\n","        features = features / np.array([np.linalg.norm(features, axis=1)]).T    # L2-normalization of features\n","        class_mean = features.mean(axis=0)  # average feature vector for the i-th seen class (64)\n","        class_mean = class_mean / np.linalg.norm(class_mean)    # L2 normalization\n","        class_means.append(class_mean)\n","\n","    return np.array(class_means)    # (seen_classes_counter, 64)\n","\n","\n","def show_heatmap_CM(labels, predictions, order_of_labels):\n","    \"\"\"\n","    Plot the confusion matrix as a heat map, given ground truth labels and the model predictions\n","    \n","    Params:\n","        labels: ground truth labels\n","        predictions: model predictions of the labels\n","\n","    Return:\n","        Show the heatmap\n","        x axis: predicted class\n","        y axis: true class\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(9,9))\n","\n","    # Build confusion matrix (as a 100x100 numpy array)\n","    cm = confusion_matrix(labels, predictions, labels=seen_classes) # classes are ordered on the x and y axis as in seen_classes array\n","\n","    # Convert the confusion matrix to a 100x100 pandas dataframe (dimensions len(labels) x len(predictions) )\n","    df_cm = pd.DataFrame(cm, seen_classes, seen_classes)\n","\n","    # Visualize the confusion matrix as a heat map\n","    ax = sns.heatmap(df_cm, cbar=False, square=False)\n","\n","    plt.show()\n","\n","\n","def CIFAR100_with_indices(cls):\n","    \"\"\"\n","    Modifies the CIFAR100 class to return a tuple (data, target, index)\n","    instead of just (data, target). index is a relative index.\n","    Ref: https://discuss.pytorch.org/t/how-to-retrieve-the-sample-indices-of-a-mini-batch/7948/19\n","    \"\"\"\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        return img, target, index\n","\n","    return type(cls.__name__, (cls,), {'__getitem__': __getitem__,})\n","\n","\n","flatten = lambda l: [item for sublist in l for item in sublist]     # from list of lists to flat list\n","\n","\n","def subset_indices(dataset, classes, exemplars_idx=[], no_exemplars=False):\n","    \"\"\"\n","    Returns the indices for the creation of a subset of a dataset containing only the images of the specified classes AND the exemplars of the previous classes\n","    \"\"\"\n","\n","    indices = []\n","\n","    # Current classes\n","    for _, img_label, img_index in dataset:\n","        if img_label in classes:\n","            indices.append(img_index)     # append the index of those images belonging to class c\n","\n","    # Exemplars of previous classes\n","    flat_list_exemplars_idx = flatten(exemplars_idx)\n","    indices.extend(flat_list_exemplars_idx)\n","\n","    return indices\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-wkPG3vuUiBK"},"source":["**Define Data Processing**"]},{"cell_type":"code","metadata":{"id":"omg4hzrgUlfR"},"source":["# Define transforms for training phase\n","train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                      transforms.RandomHorizontalFlip(p=0.5),\n","                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n","                                      transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n","                                                            std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404]) # Normalizes tensor with mean and standard deviation\n","])\n","\n","# Define transforms for the evaluation phase\n","eval_transform = transforms.Compose([transforms.Pad(4, fill=0, padding_mode='constant'),\n","                                     transforms.TenCrop(32),     # TenCrop crops the input image at the four corners and at the center with 32x32 cropping sections\n","                                     transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","                                     transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n","                                                                                                       std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404])(crop) for crop in crops]))])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZYBrIvsUl2M"},"source":["**Prepare Dataset**"]},{"cell_type":"code","metadata":{"id":"u5DSZrgzUqFP","colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["42be7813d7a0496ea0a5366595e8b76a","7d2da13e6f464baeb2923a0f900c364c","49b54dd099384a3fb07d6c7e453d0bc2","7431a30bb47b47738c735f2da8d358c6","71ad3360a1cf403786ab7d3bd3b69b92","965a443a8989415b8ae857d5c842fa4c","cf618557b23d44aa9c27d5b54f483418","c408b8349d004542b572dd4261b698ac"]},"executionInfo":{"status":"ok","timestamp":1607984305435,"user_tz":-60,"elapsed":11704,"user":{"displayName":"Tommaso Monopoli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghnx0g62sTlKYYaGZJdG5FNjVxq7rbrSNzd36V42A=s64","userId":"05588580840073678935"}},"outputId":"33721491-be18-4339-b3b7-912d6be3be78"},"source":["# This new version of the CIFAR100 class now returns (img, target, index) when you loop on it with dataloaders\n","CIFAR100 = CIFAR100_with_indices(CIFAR100)\n","\n","# Load CIFAR100 training and test datasets\n","cifar100_training = CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n","#cifar100_training_exemplars = CIFAR100(root='./data', train=True, transform=eval_transform)\n","cifar100_test = CIFAR100(root='./data', train=False, transform=eval_transform)\n","\n","# Check dataset sizes\n","print(f'Training set size: {len(cifar100_training)}')\n","print(f'Test set size: {len(cifar100_test)}')\n","\n","\n","# Create an array with a random permutation of the 100 classes (0,1,...,99), with 10 rows of 10 classes each\n","classes = np.random.permutation(np.arange(100)).reshape((10,10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42be7813d7a0496ea0a5366595e8b76a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Training set size: 50000\n","Test set size: 10000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7Ejm8r9xUuDn"},"source":["**Prepare Network**"]},{"cell_type":"code","metadata":{"id":"ynBoTE5wUzil"},"source":["from resnet_cifar import resnet32\n","net = resnet32(num_classes = 100)   # Loading ResNet32 model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5DlyxgSUz6Q"},"source":["**Define loss function**"]},{"cell_type":"code","metadata":{"id":"omEZE_sQU4Cn"},"source":["# Classification loss + distillation loss\n","criterion = nn.BCEWithLogitsLoss(reduction='mean')   # but: reduction='sum' is as seen in iCaRL paper (mean is not applied anywhere in the loss)\n","\n","# All the loss are BCEwithLogitsLoss\n","def compute_loss(outputs, one_hot_labels, classes, task_step_counter, criterion = criterion, old_outputs = None):\n","    \"\"\"\n","    Computes the loss presented in the iCaRL paper (classification loss + distillation loss),\n","    which is basically a binary cross-entropy loss, in which the \"true distribution\" vector y in the formula also includes the values of some pre-updated network outputs.\n","    Params:\n","        outputs: (BATCH_SIZE, NUM_CLASSES) matrix of logits of the current batch of images\n","        one_hot_labels: (BATCH_SIZE, NUM_CLASSES) each row is the one-hot-encoded ground-truth label of the images of the current batch.\n","        classes: the array with the random permutation of the 100 classes (10 rows with 10 classes each)\n","        old_outputs: (BATCH_SIZE, NUM_CLASSES) matrix of the pre-updated network outputs of all the nodes (not only those associated with the previously seen t-10 classes), AKA q_i values. It is None when the first set of classes is encountered.\n","        criterion: BCEWithLogitsLoss\n","    Returns:\n","        The fraction of the total loss associated with the current batch of images\n","    \"\"\"\n","\n","    if old_outputs is not None:\n","        sig = nn.Sigmoid()\n","        columns_idx_of_pre_updated_outputs = seen_classes[:-10]     # indices of the columns associated with the q_i values of the previously seen classes\n","        one_hot_labels[:, columns_idx_of_pre_updated_outputs] = sig(old_outputs[:,columns_idx_of_pre_updated_outputs])  # each row of this matrix is now the target \"true\" distribution in the cross-entropy loss to be applied\n","    \n","    loss = criterion(outputs, one_hot_labels)\n","\n","    return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73_WXopXU4PZ"},"source":["**Training and testing**"]},{"cell_type":"code","metadata":{"id":"poq9MmpnU7Pg","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1607984676182,"user_tz":-60,"elapsed":382440,"user":{"displayName":"Tommaso Monopoli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghnx0g62sTlKYYaGZJdG5FNjVxq7rbrSNzd36V42A=s64","userId":"05588580840073678935"}},"outputId":"1c751916-dd86-4435-e04d-e643f4cfb4a9"},"source":["net = net.to(DEVICE)        # this will bring the network to GPU if DEVICE is cuda\n","\n","cudnn.benchmark             # Calling this optimizes runtime\n","\n","test_acc_history = []       # this list shall contain 10 values (one for each seen class)\n","test_acc_history_CNN = []   # this list shall contain 10 values (one for each seen class)\n","\n","global_step_counter = 0     # Incremented by one every time a training iteration inside an epoch ends\n","task_step_counter = 1       # Incremented by one every time one set of 10 classes is seen\n","\n","seen_classes_counter = 0    # Incremented by 10 every time one set of 10 classes is seen\n","seen_classes = []           # Is appended with a list of the 10 classes currently seen, each time they are seen\n","\n","old_outputs = None\n","\n","exemplars_idx = [ [] for _ in range(100) ]     # a list of 100 lists which will contain m int values each; the i-th inner list will contain cifar100_training indices of exemplar images for the i-th class seen\n","\n","for current_classes in classes:     # 10 cycles (over the 10 sets of classes)\n","\n","    # Create a dataloader for the new 10 classes to train on\n","    augm_training_subset_idx = subset_indices(cifar100_training, current_classes, exemplars_idx)   # augm stands for augmented with exemplars of previous classes\n","    augm_training_subset = Subset(cifar100_training, augm_training_subset_idx)\n","    augm_training_dataloader = DataLoader(augm_training_subset, shuffle=True, num_workers=4, batch_size=BATCH_SIZE, drop_last=True)\n","    \n","    # Initialize the optimizer and the scheduler\n","    parameters_to_optimize = net.parameters()\n","    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, STEP_SIZE, gamma=GAMMA)\n","\n","\n","\n","    #################### UPDATE REPRESENTATION ####################\n","    # train on the next set of 10 unseen classes\n","\n","\n","    \n","    # 10 previously unseen classes are now being seen\n","    seen_classes_counter += 10\n","    seen_classes += current_classes.tolist()\n","\n","    epoch_step_counter = 0      # Incremented by one each time an epochs end\n","\n","    for epoch in range(NUM_EPOCHS):\n","        print(f'Starting epoch {epoch+1}/{NUM_EPOCHS}, LR = {scheduler.get_last_lr()}')\n","        t = time.time()\n","\n","        net.train(True)\n","        \n","        total_training_corrects = 0\n","        running_loss = 0\n","\n","        for images, labels, _ in augm_training_dataloader:\n","\n","            # Bring data over the device of choice\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            optimizer.zero_grad() # Zero-ing the gradients\n","\n","            # If this is not the first time classes are seen, compute the output logits of the network obtained previously\n","            if task_step_counter >= 2:\n","                old_net = torch.load('resNet_task' + str(task_step_counter - 1) + '.pt').train(False)\n","                old_outputs = old_net(images)\n","            \n","            # Forward pass to the network\n","            outputs = net(images)\n","\n","            # Compute loss\n","            one_hot_labels = torch.eye(100)[labels].to(DEVICE)\n","            loss = compute_loss(outputs, one_hot_labels,classes,task_step_counter, criterion, old_outputs)\n","            \n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update the running amount of correct predictions\n","            total_training_corrects += torch.sum(preds == labels.data).data.item()\n","\n","            # Log loss\n","            if epoch_step_counter % LOG_FREQUENCY == 0:\n","                print(f'Step: {epoch_step_counter}, training loss: {loss.item()}')\n"," \n","            # Compute gradients for each layer and update weights\n","            loss.backward()  # backward pass: computes gradients\n","            optimizer.step() # update weights based on accumulated gradients\n","\n","            # Update the local and global step counter\n","            epoch_step_counter += 1\n","            global_step_counter += 1\n","\n","        # Compute the accuracy on the current 10 classes (only for reporting purposes)\n","        current_classes_training_accuracy = total_training_corrects / (float(len(augm_training_dataloader)) * BATCH_SIZE)\n","        print(f'------ Epoch {epoch+1}/{NUM_EPOCHS} of the training on the {task_step_counter}° set of classes has ended')\n","        print(f'------ Training accuracy (only on the current 10 classes): {current_classes_training_accuracy}\\n------ Elapsed time for this epoch: {time.time() - t}')\n","\n","        # Step the scheduler\n","        scheduler.step()\n","\n","    # Save the\n","    torch.save(net, f'resNet_task{task_step_counter}.pt')\n","\n","\n","\n","    #################### EXEMPLARS MANAGEMENT ####################\n","    # exemplar management part\n","\n","\n","\n","    ###### Reduce exemplar sets of previously seen classes\n","\n","    m = int(np.ceil(K / float(seen_classes_counter)))   # NB: this can result in a number of exemplars slightly larger than K, but that's how it's done in the original iCaRL code (see main_resnet_tf.py)\n","    for i in range(seen_classes_counter - 10):\n","        exemplars_idx[i] = exemplars_idx[i][:m]\n","    \n","    ###### Construct exemplar set for each of the current 10 classes seen\n","\n","    training_subset_idx = subset_indices(cifar100_training, current_classes)   # list of 5000 indices\n","    training_subset = Subset(cifar100_training, training_subset_idx)    # subset of all training images which label is in current_classes\n","    \n","    current_classes_means = []  # at the end of the next for loop, this will be (10,64)\n","\n","    for i, cls in enumerate(current_classes): # for each current class\n","\n","        # Retrieve the 500 images of class cls\n","        class_subset_idx = subset_indices(training_subset, [cls])   # absolute indices of the 500 images of class cls\n","        class_subset_images = torch.stack([cifar100_training[j][0] for j in class_subset_idx]).cuda()  # tensor of the 500 images of class cls\n","\n","        # Compute the (exact) class mean (AKA mean feature vector) μ of class cls\n","        features = net.get_features(class_subset_images).cpu().data.numpy()     # (len(class_subset), net.fc.in_features) = (500, 64)-d matrix\n","        features = features / np.array([np.linalg.norm(features, axis=1)]).T    # normalize features (the paper mentions an L2-normalization of features)\n","        class_mean = features.mean(axis=0)  # current class mean of features (64)\n","        class_mean = class_mean / np.linalg.norm(class_mean)    # L2 normalization x / ||x||\n","        current_classes_means.append(class_mean)\n","\n","        # Construct exemplar set for class cls\n","        local_exemplars_idx = []    # relative indices of the 500 images of class cls\n","        for k in range(500):  # m; putting 500 here is a TRICK: all the 500 currently seen images will be used to compute the currently seen classes means, not the m exemplars, so they will be the exact class means\n","            temp = features[local_exemplars_idx]    # features of the k exemplars already found\n","            temp = np.sum(temp, axis=0)             #\n","            temp = features + temp                  # broadcasting! (500, 64)\n","            temp = temp / float(k+1)                # a tiny broadcasting, (500, 64)\n","            temp = class_mean - temp                # broadcasting! (500, 64)\n","            temp = np.linalg.norm(temp, axis=1)     # final norm, (500)\n","            argsort = np.argsort(temp)\n","\n","            for j in argsort:\n","                if j not in local_exemplars_idx:\n","                    exemplars_idx[(seen_classes_counter-10) + i].append(class_subset_idx[j])    # append the absolute index of the exemplar p_k to the exemplar set P_i of the i-th class\n","                    local_exemplars_idx.append(j)\n","                    break\n","\n","\n","\n","    #################### TEST PHASE ####################\n","    # NMoE classifier (see paper for mathematical details on the algorithm)\n","\n","    # Create a dataloader for the test images of all (and only) the classes seen so far\n","    test_subset_idx = subset_indices(cifar100_test, seen_classes)\n","    test_subset = Subset(cifar100_test, test_subset_idx)\n","    test_dataloader = DataLoader(test_subset, shuffle=False, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    net.train(False)    # Set Network to evaluation mode\n","\n","    # Compute the L2-normalized means-of-exemplars for the previously seen (seen_classes_counter-10) classes, and the L2-normalized (exact) class means for the currently seen 10 classes (TRICK)\n","    class_means = compute_means_of_exemplars(net, cifar100_training, exemplars_idx, seen_classes_counter)    # (seen_classes_counter, 64); USE ONLY WITH TRICK: means of exemplars of the previously seen classes and (exact) class means of the currently seen classes\n","    \n","    \n","    all_test_labels = torch.LongTensor([]).to(DEVICE)\n","    all_test_preds = torch.LongTensor([]).to(DEVICE)\n","    all_test_labels_CNN = torch.LongTensor([]).to(DEVICE)\n","    all_test_preds_CNN = torch.LongTensor([]).to(DEVICE)\n","\n","    total_test_corrects = 0\n","    total_test_corrects_CNN = 0\n","\n","    with torch.no_grad():\n","        for images, labels, _ in tqdm(test_dataloader):    # images is a (128,10,3,32,32) tensor, labels is a (128) tensor\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","            bs, ncrops, c, h, w = images.size()\n","\n","\n","\n","            ##### CLASSIFICATION WITH NME\n","            # Compute the L2-normalized feature vectors of the images of the current batch of test images\n","            features = net.get_features(images.view(-1, c, h, w)).cpu().data.numpy()    # (1280, 64)-d matrix; each row is a ϕ(x)\n","            features = features / np.array([np.linalg.norm(features, axis=1)]).T    # L2 normalization of the ϕ(x)'s\n","            #features = features.view(bs, ncrops, -1).mean(axis=1)   # (128,10,64)\n","            \n","            # Get predictions with the NMoE classifier\n","            preds = []\n","            for feature in features:\n","                pred_idx = np.argmin( np.linalg.norm(feature - class_means, axis=1) )    # relative index of the closest mean of exemplars; this indices a list in the list of lists exemplars_idx\n","                pred = cifar100_training[ exemplars_idx[pred_idx][0] ][1]   # retrieve the label associated with pred_idx; note that all the exemplars which indices are in the same list of exemplars_idx have the same label by definition\n","                preds.append(pred)\n","            preds = torch.LongTensor(preds).view(bs, ncrops)    # from (1280) to (128,10)\n","            # Hard major voting\n","            class_counts = torch.stack([torch.bincount(row, minlength=100) for row in preds])   # (128,100)\n","            preds = torch.argmax(class_counts, dim=1)   # (128)\n","\n","            preds = preds.to(DEVICE)     # to tensor (needed for the next line of code)\n","            current_batch_corrects = torch.sum(preds == labels.data).data.item()\n","\n","\n","            # Update the running statistics (for plotting purposes)\n","            total_test_corrects += current_batch_corrects\n","\n","            # Store the current batch labels and preds; needed later for plotting the heatmap\n","            all_test_labels = torch.cat((all_test_labels, labels), 0)\n","            all_test_preds = torch.cat((all_test_preds, preds), 0)\n","\n","\n","\n","            ##### CLASSIFICATION WITH CNN\n","            # Forward pass to the network\n","            outputs = net(images.view(-1, c, h, w))    # fuse batch size and ncrops (in input: (1280,3,32,32), in output: (1280,100))\n","            outputs = outputs.view(bs, ncrops, -1).mean(axis=1)      # avg over crops (128,10,100)----after mean---->(128,100)\n","            \n","            # Get predictions\n","            _, preds_CNN = torch.max(outputs.data, 1)\n","            current_batch_corrects_CNN = torch.sum(preds_CNN == labels.data).data.item()\n","\n","            # Update the running amount of correct predictions\n","            total_test_corrects_CNN += current_batch_corrects_CNN\n","\n","            # Store the current batch labels and preds; needed later for plotting the heatmap\n","            all_test_preds_CNN = torch.cat((all_test_preds, preds), 0)\n","\n","\n","\n","        test_accuracy = total_test_corrects / float(len(test_subset))\n","        test_acc_history.append(test_accuracy)\n","        test_accuracy_CNN = total_test_corrects_CNN / float(len(test_subset))\n","        test_acc_history_CNN.append(test_accuracy_CNN)\n","    \n","\n","\n","\n","\n","    ### End of training on the 10 currently seen classes\n","\n","\n","    # 10 new classes are to be seen next: update the counter\n","    task_step_counter += 1\n","\n","    print(f'--------------- Training ended on the {int(seen_classes_counter / 10)}° set of classes')\n","    print(f'--------------- Test accuracy (NME): {test_accuracy}')\n","    print(f'--------------- Test accuracy (CNN): {test_accuracy_CNN}')\n","\n","    ###### Reduce exemplar sets of currently seen classes (this is because of the trick)\n","    for i in range( seen_classes_counter-10, seen_classes_counter ):\n","        exemplars_idx[i] = exemplars_idx[i][:m]\n","\n","\n","torch.save(net, 'final_net')  # save the final net on Colab's file system\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Starting epoch 1/70, LR = [2.0]\n","Step: 0, training loss: 0.7913661003112793\n","Step: 10, training loss: 0.04946229234337807\n","Step: 20, training loss: 0.035522427409887314\n","Step: 30, training loss: 0.030085602775216103\n","------ Epoch 1/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.17447916666666666\n","------ Elapsed time for this epoch: 2.9646830558776855\n","Starting epoch 2/70, LR = [2.0]\n","Step: 40, training loss: 0.029591649770736694\n","Step: 50, training loss: 0.02491151914000511\n","Step: 60, training loss: 0.026038672775030136\n","Step: 70, training loss: 0.024393809959292412\n","------ Epoch 2/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.40965544871794873\n","------ Elapsed time for this epoch: 2.7888123989105225\n","Starting epoch 3/70, LR = [2.0]\n","Step: 80, training loss: 0.022532057017087936\n","Step: 90, training loss: 0.022642306983470917\n","Step: 100, training loss: 0.021246695891022682\n","Step: 110, training loss: 0.019937966018915176\n","------ Epoch 3/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.5010016025641025\n","------ Elapsed time for this epoch: 2.8244876861572266\n","Starting epoch 4/70, LR = [2.0]\n","Step: 120, training loss: 0.019636141136288643\n","Step: 130, training loss: 0.01825925149023533\n","Step: 140, training loss: 0.01888113282620907\n","Step: 150, training loss: 0.02040981315076351\n","------ Epoch 4/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.5757211538461539\n","------ Elapsed time for this epoch: 2.781102418899536\n","Starting epoch 5/70, LR = [2.0]\n","Step: 160, training loss: 0.016825011000037193\n","Step: 170, training loss: 0.020619487389922142\n","Step: 180, training loss: 0.0195961631834507\n","Step: 190, training loss: 0.01766461879014969\n","------ Epoch 5/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.6151842948717948\n","------ Elapsed time for this epoch: 2.818178415298462\n","Starting epoch 6/70, LR = [2.0]\n","Step: 200, training loss: 0.018239134922623634\n","Step: 210, training loss: 0.018444670364260674\n","Step: 220, training loss: 0.016663145273923874\n","Step: 230, training loss: 0.019512753933668137\n","------ Epoch 6/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.6408253205128205\n","------ Elapsed time for this epoch: 2.78310489654541\n","Starting epoch 7/70, LR = [2.0]\n","Step: 240, training loss: 0.01798582263290882\n","Step: 250, training loss: 0.015811340883374214\n","Step: 260, training loss: 0.017309796065092087\n","Step: 270, training loss: 0.015784673392772675\n","------ Epoch 7/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.6440304487179487\n","------ Elapsed time for this epoch: 2.794509172439575\n","Starting epoch 8/70, LR = [2.0]\n","Step: 280, training loss: 0.018165946006774902\n","Step: 290, training loss: 0.013543190434575081\n","Step: 300, training loss: 0.014018086716532707\n","Step: 310, training loss: 0.017665909603238106\n","------ Epoch 8/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.6895032051282052\n","------ Elapsed time for this epoch: 2.8175737857818604\n","Starting epoch 9/70, LR = [2.0]\n","Step: 320, training loss: 0.016308357939124107\n","Step: 330, training loss: 0.014430816285312176\n","Step: 340, training loss: 0.016512392088770866\n","Step: 350, training loss: 0.014981305226683617\n","------ Epoch 9/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.6872996794871795\n","------ Elapsed time for this epoch: 2.8220834732055664\n","Starting epoch 10/70, LR = [2.0]\n","Step: 360, training loss: 0.013113811612129211\n","Step: 370, training loss: 0.014930139295756817\n","Step: 380, training loss: 0.01395984273403883\n","------ Epoch 10/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7009214743589743\n","------ Elapsed time for this epoch: 2.849125623703003\n","Starting epoch 11/70, LR = [2.0]\n","Step: 390, training loss: 0.012666866183280945\n","Step: 400, training loss: 0.015714380890130997\n","Step: 410, training loss: 0.013640157878398895\n","Step: 420, training loss: 0.01278136670589447\n","------ Epoch 11/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7199519230769231\n","------ Elapsed time for this epoch: 2.831774950027466\n","Starting epoch 12/70, LR = [2.0]\n","Step: 430, training loss: 0.012931176461279392\n","Step: 440, training loss: 0.012633638456463814\n","Step: 450, training loss: 0.012200526893138885\n","Step: 460, training loss: 0.011204187758266926\n","------ Epoch 12/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7407852564102564\n","------ Elapsed time for this epoch: 2.817939281463623\n","Starting epoch 13/70, LR = [2.0]\n","Step: 470, training loss: 0.015054375864565372\n","Step: 480, training loss: 0.01310355868190527\n","Step: 490, training loss: 0.01224325131624937\n","Step: 500, training loss: 0.013534612022340298\n","------ Epoch 13/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7389823717948718\n","------ Elapsed time for this epoch: 2.7864906787872314\n","Starting epoch 14/70, LR = [2.0]\n","Step: 510, training loss: 0.012318672612309456\n","Step: 520, training loss: 0.009674932807683945\n","Step: 530, training loss: 0.010746024549007416\n","Step: 540, training loss: 0.013830067589879036\n","------ Epoch 14/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7624198717948718\n","------ Elapsed time for this epoch: 2.8424556255340576\n","Starting epoch 15/70, LR = [2.0]\n","Step: 550, training loss: 0.011854002252221107\n","Step: 560, training loss: 0.01160298753529787\n","Step: 570, training loss: 0.012799068354070187\n","Step: 580, training loss: 0.010465102270245552\n","------ Epoch 15/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7692307692307693\n","------ Elapsed time for this epoch: 2.8310036659240723\n","Starting epoch 16/70, LR = [2.0]\n","Step: 590, training loss: 0.009974689222872257\n","Step: 600, training loss: 0.013383128680288792\n","Step: 610, training loss: 0.011965659447014332\n","Step: 620, training loss: 0.011268062517046928\n","------ Epoch 16/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7802483974358975\n","------ Elapsed time for this epoch: 2.837778091430664\n","Starting epoch 17/70, LR = [2.0]\n","Step: 630, training loss: 0.011004967615008354\n","Step: 640, training loss: 0.011081445030868053\n","Step: 650, training loss: 0.011055439710617065\n","Step: 660, training loss: 0.011819902807474136\n","------ Epoch 17/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7802483974358975\n","------ Elapsed time for this epoch: 2.8902077674865723\n","Starting epoch 18/70, LR = [2.0]\n","Step: 670, training loss: 0.010657417587935925\n","Step: 680, training loss: 0.010066036134958267\n","Step: 690, training loss: 0.010606285184621811\n","Step: 700, training loss: 0.011305497959256172\n","------ Epoch 18/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7880608974358975\n","------ Elapsed time for this epoch: 2.856557607650757\n","Starting epoch 19/70, LR = [2.0]\n","Step: 710, training loss: 0.010581190697848797\n","Step: 720, training loss: 0.011046800762414932\n","Step: 730, training loss: 0.011724165640771389\n","Step: 740, training loss: 0.00952078215777874\n","------ Epoch 19/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8000801282051282\n","------ Elapsed time for this epoch: 2.8818304538726807\n","Starting epoch 20/70, LR = [2.0]\n","Step: 750, training loss: 0.00987863726913929\n","Step: 760, training loss: 0.011690923944115639\n","Step: 770, training loss: 0.007953101769089699\n","------ Epoch 20/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.7972756410256411\n","------ Elapsed time for this epoch: 2.845949172973633\n","Starting epoch 21/70, LR = [2.0]\n","Step: 780, training loss: 0.011142301373183727\n","Step: 790, training loss: 0.010775892063975334\n","Step: 800, training loss: 0.007424221374094486\n","Step: 810, training loss: 0.009460090659558773\n","------ Epoch 21/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8094951923076923\n","------ Elapsed time for this epoch: 2.8501193523406982\n","Starting epoch 22/70, LR = [2.0]\n","Step: 820, training loss: 0.007933076471090317\n","Step: 830, training loss: 0.007299946155399084\n","Step: 840, training loss: 0.010067036375403404\n","Step: 850, training loss: 0.010187643580138683\n","------ Epoch 22/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8181089743589743\n","------ Elapsed time for this epoch: 2.8494553565979004\n","Starting epoch 23/70, LR = [2.0]\n","Step: 860, training loss: 0.007623353041708469\n","Step: 870, training loss: 0.007652498781681061\n","Step: 880, training loss: 0.006916212849318981\n","Step: 890, training loss: 0.009264539927244186\n","------ Epoch 23/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8269230769230769\n","------ Elapsed time for this epoch: 2.8585569858551025\n","Starting epoch 24/70, LR = [2.0]\n","Step: 900, training loss: 0.008878462947905064\n","Step: 910, training loss: 0.006471636239439249\n","Step: 920, training loss: 0.00994538702070713\n","Step: 930, training loss: 0.00874476321041584\n","------ Epoch 24/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8319310897435898\n","------ Elapsed time for this epoch: 2.871347188949585\n","Starting epoch 25/70, LR = [2.0]\n","Step: 940, training loss: 0.0077794692479074\n","Step: 950, training loss: 0.009915638715028763\n","Step: 960, training loss: 0.007723809685558081\n","Step: 970, training loss: 0.008949813432991505\n","------ Epoch 25/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8431490384615384\n","------ Elapsed time for this epoch: 2.892244338989258\n","Starting epoch 26/70, LR = [2.0]\n","Step: 980, training loss: 0.007296761032193899\n","Step: 990, training loss: 0.011356297880411148\n","Step: 1000, training loss: 0.007669926155358553\n","Step: 1010, training loss: 0.009381730109453201\n","------ Epoch 26/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8417467948717948\n","------ Elapsed time for this epoch: 2.8645925521850586\n","Starting epoch 27/70, LR = [2.0]\n","Step: 1020, training loss: 0.006613205652683973\n","Step: 1030, training loss: 0.009577592834830284\n","Step: 1040, training loss: 0.007463730406016111\n","Step: 1050, training loss: 0.006263399962335825\n","------ Epoch 27/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8543669871794872\n","------ Elapsed time for this epoch: 2.8550281524658203\n","Starting epoch 28/70, LR = [2.0]\n","Step: 1060, training loss: 0.005683650728315115\n","Step: 1070, training loss: 0.0067762634716928005\n","Step: 1080, training loss: 0.006618069484829903\n","Step: 1090, training loss: 0.008413725532591343\n","------ Epoch 28/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8629807692307693\n","------ Elapsed time for this epoch: 2.828528642654419\n","Starting epoch 29/70, LR = [2.0]\n","Step: 1100, training loss: 0.005658137612044811\n","Step: 1110, training loss: 0.005623650271445513\n","Step: 1120, training loss: 0.007088882848620415\n","Step: 1130, training loss: 0.008217331022024155\n","------ Epoch 29/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8617788461538461\n","------ Elapsed time for this epoch: 2.8821330070495605\n","Starting epoch 30/70, LR = [2.0]\n","Step: 1140, training loss: 0.008146190084517002\n","Step: 1150, training loss: 0.004712916910648346\n","Step: 1160, training loss: 0.008724464103579521\n","------ Epoch 30/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8721955128205128\n","------ Elapsed time for this epoch: 2.9442026615142822\n","Starting epoch 31/70, LR = [2.0]\n","Step: 1170, training loss: 0.007727966643869877\n","Step: 1180, training loss: 0.006963840685784817\n","Step: 1190, training loss: 0.006228714250028133\n","Step: 1200, training loss: 0.008430234156548977\n","------ Epoch 31/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8701923076923077\n","------ Elapsed time for this epoch: 2.879376173019409\n","Starting epoch 32/70, LR = [2.0]\n","Step: 1210, training loss: 0.006958770100027323\n","Step: 1220, training loss: 0.006005457602441311\n","Step: 1230, training loss: 0.005181363318115473\n","Step: 1240, training loss: 0.005453038029372692\n","------ Epoch 32/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8760016025641025\n","------ Elapsed time for this epoch: 2.866082191467285\n","Starting epoch 33/70, LR = [2.0]\n","Step: 1250, training loss: 0.00535186380147934\n","Step: 1260, training loss: 0.005872209556400776\n","Step: 1270, training loss: 0.005753577686846256\n","Step: 1280, training loss: 0.007974701933562756\n","------ Epoch 33/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8693910256410257\n","------ Elapsed time for this epoch: 2.865194082260132\n","Starting epoch 34/70, LR = [2.0]\n","Step: 1290, training loss: 0.004274529870599508\n","Step: 1300, training loss: 0.008503992110490799\n","Step: 1310, training loss: 0.006589759606868029\n","Step: 1320, training loss: 0.006439190823584795\n","------ Epoch 34/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8818108974358975\n","------ Elapsed time for this epoch: 2.894365072250366\n","Starting epoch 35/70, LR = [2.0]\n","Step: 1330, training loss: 0.007232164032757282\n","Step: 1340, training loss: 0.006319536827504635\n","Step: 1350, training loss: 0.0066287037916481495\n","Step: 1360, training loss: 0.005387244280427694\n","------ Epoch 35/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8936298076923077\n","------ Elapsed time for this epoch: 2.884833574295044\n","Starting epoch 36/70, LR = [2.0]\n","Step: 1370, training loss: 0.006532765459269285\n","Step: 1380, training loss: 0.00611030263826251\n","Step: 1390, training loss: 0.005317237228155136\n","Step: 1400, training loss: 0.007180949207395315\n","------ Epoch 36/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8902243589743589\n","------ Elapsed time for this epoch: 2.9851865768432617\n","Starting epoch 37/70, LR = [2.0]\n","Step: 1410, training loss: 0.005279166623950005\n","Step: 1420, training loss: 0.0060347095131874084\n","Step: 1430, training loss: 0.0044350107200443745\n","Step: 1440, training loss: 0.007180165499448776\n","------ Epoch 37/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9004407051282052\n","------ Elapsed time for this epoch: 2.9606659412384033\n","Starting epoch 38/70, LR = [2.0]\n","Step: 1450, training loss: 0.005715520121157169\n","Step: 1460, training loss: 0.004806397948414087\n","Step: 1470, training loss: 0.0035135250072926283\n","Step: 1480, training loss: 0.007492557168006897\n","------ Epoch 38/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8968349358974359\n","------ Elapsed time for this epoch: 2.9525701999664307\n","Starting epoch 39/70, LR = [2.0]\n","Step: 1490, training loss: 0.005644828546792269\n","Step: 1500, training loss: 0.006240822374820709\n","Step: 1510, training loss: 0.005658780690282583\n","Step: 1520, training loss: 0.006534926127642393\n","------ Epoch 39/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9002403846153846\n","------ Elapsed time for this epoch: 2.963740110397339\n","Starting epoch 40/70, LR = [2.0]\n","Step: 1530, training loss: 0.005340748932212591\n","Step: 1540, training loss: 0.007851614616811275\n","Step: 1550, training loss: 0.005856593605130911\n","------ Epoch 40/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8990384615384616\n","------ Elapsed time for this epoch: 2.9078385829925537\n","Starting epoch 41/70, LR = [2.0]\n","Step: 1560, training loss: 0.006088957656174898\n","Step: 1570, training loss: 0.0064286706037819386\n","Step: 1580, training loss: 0.005044861230999231\n","Step: 1590, training loss: 0.00680082431063056\n","------ Epoch 41/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.8962339743589743\n","------ Elapsed time for this epoch: 2.8563528060913086\n","Starting epoch 42/70, LR = [2.0]\n","Step: 1600, training loss: 0.0065843635238707066\n","Step: 1610, training loss: 0.005599652417004108\n","Step: 1620, training loss: 0.003783712862059474\n","Step: 1630, training loss: 0.0031768009066581726\n","------ Epoch 42/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9036458333333334\n","------ Elapsed time for this epoch: 2.8567898273468018\n","Starting epoch 43/70, LR = [2.0]\n","Step: 1640, training loss: 0.003956816624850035\n","Step: 1650, training loss: 0.005719638895243406\n","Step: 1660, training loss: 0.0065845646895468235\n","Step: 1670, training loss: 0.006267726421356201\n","------ Epoch 43/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9092548076923077\n","------ Elapsed time for this epoch: 2.872072219848633\n","Starting epoch 44/70, LR = [2.0]\n","Step: 1680, training loss: 0.003378356108441949\n","Step: 1690, training loss: 0.0058198184706270695\n","Step: 1700, training loss: 0.004062871914356947\n","Step: 1710, training loss: 0.005452184472233057\n","------ Epoch 44/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9042467948717948\n","------ Elapsed time for this epoch: 2.891563653945923\n","Starting epoch 45/70, LR = [2.0]\n","Step: 1720, training loss: 0.003988148178905249\n","Step: 1730, training loss: 0.0070633916184306145\n","Step: 1740, training loss: 0.004150245804339647\n","Step: 1750, training loss: 0.006459751166403294\n","------ Epoch 45/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9038461538461539\n","------ Elapsed time for this epoch: 2.889814853668213\n","Starting epoch 46/70, LR = [2.0]\n","Step: 1760, training loss: 0.004398803226649761\n","Step: 1770, training loss: 0.00476307375356555\n","Step: 1780, training loss: 0.005350854247808456\n","Step: 1790, training loss: 0.0040213908068835735\n","------ Epoch 46/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9164663461538461\n","------ Elapsed time for this epoch: 2.8965227603912354\n","Starting epoch 47/70, LR = [2.0]\n","Step: 1800, training loss: 0.004951043054461479\n","Step: 1810, training loss: 0.003876448841765523\n","Step: 1820, training loss: 0.006113632582128048\n","Step: 1830, training loss: 0.0064531294628977776\n","------ Epoch 47/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9160657051282052\n","------ Elapsed time for this epoch: 2.8769149780273438\n","Starting epoch 48/70, LR = [2.0]\n","Step: 1840, training loss: 0.005119229666888714\n","Step: 1850, training loss: 0.0037899084854871035\n","Step: 1860, training loss: 0.003974446095526218\n","Step: 1870, training loss: 0.005613214801996946\n","------ Epoch 48/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9178685897435898\n","------ Elapsed time for this epoch: 2.8857789039611816\n","Starting epoch 49/70, LR = [2.0]\n","Step: 1880, training loss: 0.003869357518851757\n","Step: 1890, training loss: 0.004718865267932415\n","Step: 1900, training loss: 0.007115452084690332\n","Step: 1910, training loss: 0.004157138988375664\n","------ Epoch 49/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9124599358974359\n","------ Elapsed time for this epoch: 2.883971929550171\n","Starting epoch 50/70, LR = [0.4]\n","Step: 1920, training loss: 0.0034107379615306854\n","Step: 1930, training loss: 0.0030711416620761156\n","Step: 1940, training loss: 0.0031529751140624285\n","------ Epoch 50/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9493189102564102\n","------ Elapsed time for this epoch: 2.875521183013916\n","Starting epoch 51/70, LR = [0.4]\n","Step: 1950, training loss: 0.002132557099685073\n","Step: 1960, training loss: 0.0019470399711281061\n","Step: 1970, training loss: 0.001753944088704884\n","Step: 1980, training loss: 0.0015825902810320258\n","------ Epoch 51/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9649439102564102\n","------ Elapsed time for this epoch: 2.867518901824951\n","Starting epoch 52/70, LR = [0.4]\n","Step: 1990, training loss: 0.0020024655386805534\n","Step: 2000, training loss: 0.0012214124435558915\n","Step: 2010, training loss: 0.003327231388539076\n","Step: 2020, training loss: 0.0014118703547865152\n","------ Epoch 52/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9725560897435898\n","------ Elapsed time for this epoch: 2.8797783851623535\n","Starting epoch 53/70, LR = [0.4]\n","Step: 2030, training loss: 0.0016256076050922275\n","Step: 2040, training loss: 0.001586425001733005\n","Step: 2050, training loss: 0.001788673922419548\n","Step: 2060, training loss: 0.0019461348420009017\n","------ Epoch 53/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9709535256410257\n","------ Elapsed time for this epoch: 2.843675374984741\n","Starting epoch 54/70, LR = [0.4]\n","Step: 2070, training loss: 0.0019248465541750193\n","Step: 2080, training loss: 0.0015246433904394507\n","Step: 2090, training loss: 0.0015097325667738914\n","Step: 2100, training loss: 0.002483959309756756\n","------ Epoch 54/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9731570512820513\n","------ Elapsed time for this epoch: 2.8825151920318604\n","Starting epoch 55/70, LR = [0.4]\n","Step: 2110, training loss: 0.0021893195807933807\n","Step: 2120, training loss: 0.0016718956176191568\n","Step: 2130, training loss: 0.0017915057251229882\n","Step: 2140, training loss: 0.0015346130821853876\n","------ Epoch 55/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9745592948717948\n","------ Elapsed time for this epoch: 2.885099172592163\n","Starting epoch 56/70, LR = [0.4]\n","Step: 2150, training loss: 0.002117991214618087\n","Step: 2160, training loss: 0.0027059486601501703\n","Step: 2170, training loss: 0.0010104714892804623\n","Step: 2180, training loss: 0.0016717991093173623\n","------ Epoch 56/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9787660256410257\n","------ Elapsed time for this epoch: 2.8862833976745605\n","Starting epoch 57/70, LR = [0.4]\n","Step: 2190, training loss: 0.0017242026515305042\n","Step: 2200, training loss: 0.0009622465586289763\n","Step: 2210, training loss: 0.0008179001160897315\n","Step: 2220, training loss: 0.001713306293822825\n","------ Epoch 57/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9775641025641025\n","------ Elapsed time for this epoch: 2.875852108001709\n","Starting epoch 58/70, LR = [0.4]\n","Step: 2230, training loss: 0.0012032424565404654\n","Step: 2240, training loss: 0.0008627783390693367\n","Step: 2250, training loss: 0.0009303624974563718\n","Step: 2260, training loss: 0.0009132260456681252\n","------ Epoch 58/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9797676282051282\n","------ Elapsed time for this epoch: 2.8752875328063965\n","Starting epoch 59/70, LR = [0.4]\n","Step: 2270, training loss: 0.0014389127027243376\n","Step: 2280, training loss: 0.0015700238291174173\n","Step: 2290, training loss: 0.001278143492527306\n","Step: 2300, training loss: 0.0008528212201781571\n","------ Epoch 59/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9833733974358975\n","------ Elapsed time for this epoch: 2.860963821411133\n","Starting epoch 60/70, LR = [0.4]\n","Step: 2310, training loss: 0.0011850938899442554\n","Step: 2320, training loss: 0.0006029504002071917\n","Step: 2330, training loss: 0.0009662072407081723\n","------ Epoch 60/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9817708333333334\n","------ Elapsed time for this epoch: 2.928875207901001\n","Starting epoch 61/70, LR = [0.4]\n","Step: 2340, training loss: 0.0010997102363035083\n","Step: 2350, training loss: 0.001118568005040288\n","Step: 2360, training loss: 0.0007718169363215566\n","Step: 2370, training loss: 0.0008460951503366232\n","------ Epoch 61/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9813701923076923\n","------ Elapsed time for this epoch: 2.8827412128448486\n","Starting epoch 62/70, LR = [0.4]\n","Step: 2380, training loss: 0.0011909505119547248\n","Step: 2390, training loss: 0.0020172125659883022\n","Step: 2400, training loss: 0.0008645651396363974\n","Step: 2410, training loss: 0.0024960103910416365\n","------ Epoch 62/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9829727564102564\n","------ Elapsed time for this epoch: 2.8917717933654785\n","Starting epoch 63/70, LR = [0.4]\n","Step: 2420, training loss: 0.0015346754807978868\n","Step: 2430, training loss: 0.0016531558940187097\n","Step: 2440, training loss: 0.0021805211436003447\n","Step: 2450, training loss: 0.0011728336103260517\n","------ Epoch 63/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9839743589743589\n","------ Elapsed time for this epoch: 2.891042709350586\n","Starting epoch 64/70, LR = [0.08000000000000002]\n","Step: 2460, training loss: 0.0012016923865303397\n","Step: 2470, training loss: 0.0009793669451028109\n","Step: 2480, training loss: 0.0013105242978781462\n","Step: 2490, training loss: 0.0010711787035688758\n","------ Epoch 64/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9847756410256411\n","------ Elapsed time for this epoch: 2.9542195796966553\n","Starting epoch 65/70, LR = [0.08000000000000002]\n","Step: 2500, training loss: 0.0011667850194498897\n","Step: 2510, training loss: 0.0007127022836357355\n","Step: 2520, training loss: 0.0005713747814297676\n","Step: 2530, training loss: 0.001330512692220509\n","------ Epoch 65/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9899839743589743\n","------ Elapsed time for this epoch: 2.9315872192382812\n","Starting epoch 66/70, LR = [0.08000000000000002]\n","Step: 2540, training loss: 0.0024096083361655474\n","Step: 2550, training loss: 0.0012870614882558584\n","Step: 2560, training loss: 0.0010712912771850824\n","Step: 2570, training loss: 0.0014908682787790895\n","------ Epoch 66/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9881810897435898\n","------ Elapsed time for this epoch: 2.928962230682373\n","Starting epoch 67/70, LR = [0.08000000000000002]\n","Step: 2580, training loss: 0.0006277442444115877\n","Step: 2590, training loss: 0.0015313089825212955\n","Step: 2600, training loss: 0.0007054971647448838\n","Step: 2610, training loss: 0.0005979759152978659\n","------ Epoch 67/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9893830128205128\n","------ Elapsed time for this epoch: 2.8795924186706543\n","Starting epoch 68/70, LR = [0.08000000000000002]\n","Step: 2620, training loss: 0.0013925611274316907\n","Step: 2630, training loss: 0.0015682245139032602\n","Step: 2640, training loss: 0.0005768110859207809\n","Step: 2650, training loss: 0.0011343995574861765\n","------ Epoch 68/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9893830128205128\n","------ Elapsed time for this epoch: 2.886932134628296\n","Starting epoch 69/70, LR = [0.08000000000000002]\n","Step: 2660, training loss: 0.0015261635417118669\n","Step: 2670, training loss: 0.0005367929697968066\n","Step: 2680, training loss: 0.0008514607325196266\n","Step: 2690, training loss: 0.0015909954672679305\n","------ Epoch 69/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9855769230769231\n","------ Elapsed time for this epoch: 2.8720452785491943\n","Starting epoch 70/70, LR = [0.08000000000000002]\n","Step: 2700, training loss: 0.000735802692361176\n","Step: 2710, training loss: 0.0008560736896470189\n","Step: 2720, training loss: 0.00043092979467473924\n","------ Epoch 70/70 of the training on the 1° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.9905849358974359\n","------ Elapsed time for this epoch: 2.8739373683929443\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["--------------- Training ended on the 1° set of classes\n","--------------- Test accuracy (NME): 0.862\n","--------------- Test accuracy (CNN): 0.87\n","Starting epoch 1/70, LR = [2.0]\n","Step: 0, training loss: 0.0891089215874672\n","Step: 10, training loss: 0.056843239814043045\n","Step: 20, training loss: 0.04061124101281166\n","Step: 30, training loss: 0.03632091358304024\n","Step: 40, training loss: 0.03380727395415306\n","Step: 50, training loss: 0.034197792410850525\n","------ Epoch 1/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.2760416666666667\n","------ Elapsed time for this epoch: 7.841755390167236\n","Starting epoch 2/70, LR = [2.0]\n","Step: 60, training loss: 0.032131828367710114\n","Step: 70, training loss: 0.0278193186968565\n","Step: 80, training loss: 0.028527608141303062\n","Step: 90, training loss: 0.027653750032186508\n","Step: 100, training loss: 0.02910902164876461\n","------ Epoch 2/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.3521412037037037\n","------ Elapsed time for this epoch: 7.649114370346069\n","Starting epoch 3/70, LR = [2.0]\n","Step: 110, training loss: 0.02585487812757492\n","Step: 120, training loss: 0.025206979364156723\n","Step: 130, training loss: 0.024788331240415573\n","Step: 140, training loss: 0.025289662182331085\n","Step: 150, training loss: 0.026277314871549606\n","Step: 160, training loss: 0.027795640751719475\n","------ Epoch 3/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.41594328703703703\n","------ Elapsed time for this epoch: 7.762418031692505\n","Starting epoch 4/70, LR = [2.0]\n","Step: 170, training loss: 0.025151537731289864\n","Step: 180, training loss: 0.02774239517748356\n","Step: 190, training loss: 0.02400725707411766\n","Step: 200, training loss: 0.02507816255092621\n","Step: 210, training loss: 0.02484430931508541\n","------ Epoch 4/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.4544270833333333\n","------ Elapsed time for this epoch: 7.7834014892578125\n","Starting epoch 5/70, LR = [2.0]\n","Step: 220, training loss: 0.02589261904358864\n","Step: 230, training loss: 0.02544560097157955\n","Step: 240, training loss: 0.025507532060146332\n","Step: 250, training loss: 0.024320723488926888\n","Step: 260, training loss: 0.025049487128853798\n","------ Epoch 5/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.48726851851851855\n","------ Elapsed time for this epoch: 7.734012842178345\n","Starting epoch 6/70, LR = [2.0]\n","Step: 270, training loss: 0.02380203828215599\n","Step: 280, training loss: 0.02342287451028824\n","Step: 290, training loss: 0.026031726971268654\n","Step: 300, training loss: 0.023871254175901413\n","Step: 310, training loss: 0.02664889767765999\n","Step: 320, training loss: 0.023227985948324203\n","------ Epoch 6/70 of the training on the 2° set of classes has ended\n","------ Training accuracy (only on the current 10 classes): 0.5209780092592593\n","------ Elapsed time for this epoch: 7.784683465957642\n","Starting epoch 7/70, LR = [2.0]\n","Step: 330, training loss: 0.023076146841049194\n","Step: 340, training loss: 0.022048737853765488\n","Step: 350, training loss: 0.02664104476571083\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-d653798f93f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mone_hot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask_step_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sORKQtDcKGNt"},"source":["# Print the ten test accuracies obtained\n","print(test_acc_history)\n","print(test_acc_history_CNN)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0xjbReTSV2s0"},"source":["**Heatmap Confusion Matrix**"]},{"cell_type":"code","metadata":{"id":"xUD5NbMvnSMo"},"source":["# Show the confusion matrix for the test set as a heatmap\n","show_heatmap_CM(all_test_labels.cpu(), all_test_preds.cpu(), order_of_labels=seen_classes)"],"execution_count":null,"outputs":[]}]}