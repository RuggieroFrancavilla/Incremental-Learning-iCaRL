{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Less Forget Loss - ICarl.ipynb","provenance":[{"file_id":"1n7pb9QO2HFHYSvTd2VpWbC5PXzYy2Jcc","timestamp":1605609502240},{"file_id":"1vHl4DuA5sgbkRmCtKarY8lkZ7Lg12iN7","timestamp":1605344027431},{"file_id":"14_dItIxy-IsjIf5e5twpTJNzKwbN878l","timestamp":1604417498953},{"file_id":"1S9l0AeljfsQsCkSbVn9RsSkISD9VlLLV","timestamp":1591951315087}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"01mnXmFnUFdV"},"source":["**Import libraries**\n"]},{"cell_type":"code","metadata":{"id":"crURUb9gURME"},"source":["import time\n","from copy import deepcopy\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset, DataLoader\n","from torch.backends import cudnn\n","from torch.nn.functional import one_hot\n","\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR100\n","from torchvision.models import resnet\n","\n","import numpy as np\n","from numpy.linalg import norm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import seaborn as sns\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Load cosine_resnet_cifar.py\n","import os\n","if not os.path.exists(\"./cosine_resnet_cifar.py\"):\n","    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1aLzDvalo3n5T7nLtPgkPM3nIeEgukL-9' -O cosine_resnet_cifar.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"US3YGeI1UT4U"},"source":["**Set Arguments**\n"]},{"cell_type":"code","metadata":{"id":"Rn1Q6EXlUbQS"},"source":["DEVICE = 'cuda'\n","\n","BATCH_SIZE = 128\n","\n","K = 2000\n","NUM_EPOCHS =  70\n","\n","# Hyperparameters for Less-forget constraint and Inter-class separation\n","LAMDA_BASE = 3.5\n","KK = 3\n","MARGIN = 1\n","\n","LR = 0.1\n","MOMENTUM = 0.9\n","STEP_SIZE = [49,63]\n","GAMMA = 0.1\n","WEIGHT_DECAY = 5e-4\n","LOG_FREQUENCY = 10\n","\n","# Random seeds\n","np.random.seed(653)\n","torch.manual_seed(653)\n","torch.cuda.manual_seed(653)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SIttza66zgeP"},"source":["**Some utility functions**"]},{"cell_type":"code","metadata":{"id":"fJ01T0SdzfpZ"},"source":["def compute_means_of_exemplars(net, dataset, exemplars_idx, n):\n","    \"\"\"\n","    Compute the L2-normalized mean-of-exemplars (AKA average feature vectors) for the first n classes seen\n","    Returns:\n","        a (seen_classes_counter, 64) numpy array whose rows are the mean-of-exemplars of the seen_classes_counter classes seen so far, computed using the current exemplars\n","    \"\"\"\n","    if n == 0:    # if seen_classes_counter = 0 then return an empty array\n","        return np.array([]).reshape((0,64))\n","    \n","    class_means = []    # this will contain seen_classes_counter lists; i-th list will contain the L2-normalized mean-of-exemplars for the i-th seen class\n","\n","    for i in range(n):   # for each i-th seen class\n","\n","        # Retrieve the exemplars of the i-th seen class\n","        list_exemplars = [dataset[exemplar_idx][0] for exemplar_idx in exemplars_idx[i]]    # a list of tensors, containing the m exemplars of the i-th seen class\n","        exemplars_images = torch.stack(list_exemplars).cuda()     # a tensor containing the m exemplars of the i-th seen class    \n","\n","        # Compute the average feature vector of the i-th seen class\n","        features = net.get_features(exemplars_images).cpu().data.numpy()    # feature vectors of the m exemplars of the i-th seen class (m, 64)\n","        features = features / np.array([np.linalg.norm(features, axis=1)]).T    # L2-normalization of features\n","        class_mean = features.mean(axis=0)  # average feature vector for the i-th seen class (64)\n","        class_mean = class_mean / np.linalg.norm(class_mean)    # L2 normalization\n","        class_means.append(class_mean)\n","\n","    return np.array(class_means)    # (seen_classes_counter, 64)\n","\n","\n","def show_heatmap_CM(labels, predictions):\n","    \"\"\"\n","    Plot the confusion matrix as a heat map, given ground truth labels and the model predictions\n","    \n","    Params:\n","        labels: ground truth labels\n","        predictions: model predictions of the labels\n","\n","    Return:\n","        Show the heatmap\n","        x axis: predicted class\n","        y axis: true class\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(9,9))\n","\n","    # Build confusion matrix (as a 100x100 numpy array)\n","    cm = confusion_matrix(labels, predictions, labels=seen_classes)\n","\n","    # Convert the confusion matrix to a 100x100 pandas dataframe (dimensions len(labels) x len(predictions) )\n","    df_cm = pd.DataFrame(cm, seen_classes, seen_classes)\n","    df_cm.columns = np.arange(100)+20    # for plotting reasons\n","    df_cm.index = np.arange(100)+20    # for plotting reasons\n","\n","    # Visualize the confusion matrix as a heat map\n","    ax = sns.heatmap(df_cm, xticklabels=20, yticklabels=20, cbar=False, square=False, cmap='OrRd')\n","    sns.set(font_scale = 2)\n","    ax.set(xlabel='Predicted class', ylabel='True class')\n","    pos, textvals = plt.xticks()\n","    plt.xticks(np.array(pos)+20, textvals, va=\"center\")\n","    pos, textvals = plt.yticks()\n","    plt.yticks(np.array(pos)+20, textvals, va=\"center\")\n","    ax.tick_params(axis='x', pad=15)\n","\n","    plt.show()\n","\n","\n","def CIFAR100_with_indices(cls):\n","    \"\"\"\n","    Modifies the CIFAR100 class to return a tuple (data, target, index)\n","    instead of just (data, target). index is a relative index.\n","    Ref: https://discuss.pytorch.org/t/how-to-retrieve-the-sample-indices-of-a-mini-batch/7948/19\n","    \"\"\"\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        return img, target, index\n","\n","    return type(cls.__name__, (cls,), {'__getitem__': __getitem__,})\n","\n","\n","flatten = lambda l: [item for sublist in l for item in sublist]     # from list of lists to flat list\n","\n","\n","def subset_indices(dataset, classes, exemplars_idx=[], no_exemplars=False):\n","    \"\"\"\n","    Returns the indices for the creation of a subset of a dataset containing only the images of the specified classes AND the exemplars of the previous classes\n","    \"\"\"\n","\n","    indices = []\n","\n","    # Current classes\n","    for _, img_label, img_index in dataset:\n","        if img_label in classes:\n","            indices.append(img_index)     # append the index of those images belonging to class c\n","\n","    # Exemplars of previous classes\n","    flat_list_exemplars_idx = flatten(exemplars_idx)\n","    indices.extend(flat_list_exemplars_idx)\n","\n","    return indices\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-wkPG3vuUiBK"},"source":["**Define Data Processing**"]},{"cell_type":"code","metadata":{"id":"omg4hzrgUlfR"},"source":["# Define transforms for training phase\n","train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                      transforms.RandomHorizontalFlip(p=0.5),\n","                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n","                                      transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n","                                                            std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404]) # Normalizes tensor with mean and standard deviation\n","])\n","\n","# Define transforms for the evaluation phase\n","eval_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n","                                                            std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404])                                    \n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZYBrIvsUl2M"},"source":["**Prepare Dataset**"]},{"cell_type":"code","metadata":{"id":"u5DSZrgzUqFP"},"source":["# This new version of the CIFAR100 class now returns (img, target, index) when you loop on it with dataloaders\n","CIFAR100 = CIFAR100_with_indices(CIFAR100)\n","\n","# Load CIFAR100 training and test datasets\n","cifar100_training = CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n","#cifar100_training_exemplars = CIFAR100(root='./data', train=True, transform = eval_transform)\n","cifar100_test = CIFAR100(root='./data', train=False, transform=eval_transform)\n","\n","# Check dataset sizes\n","print(f'Training set size: {len(cifar100_training)}')\n","print(f'Test set size: {len(cifar100_test)}')\n","\n","\n","# Create an array with a random permutation of the 100 classes, with 10 rows of 10 classes each\n","classes = np.random.permutation(np.arange(100)).reshape((10,10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ejm8r9xUuDn"},"source":["**Prepare Network**"]},{"cell_type":"code","metadata":{"id":"ynBoTE5wUzil"},"source":["from cosine_resnet_cifar import resnet32\n","net = resnet32(num_classes = 100)   # Loading ResNet32 model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5DlyxgSUz6Q"},"source":["**Define loss function**"]},{"cell_type":"code","metadata":{"id":"omEZE_sQU4Cn"},"source":["# Classification loss + less-forget constraint + inter-class separation\n","criterion = nn.CrossEntropyLoss(reduction='mean')\n","criterion_LF = nn.CosineEmbeddingLoss(reduction='mean')\n","criterion_IS = nn.MarginRankingLoss(margin=MARGIN, reduction='mean')\n","\n","def compute_loss(outputs, images, labels, net, current_classes, seen_classes_counter, old_net = None):\n","    num_old_classes = seen_classes_counter - 10\n","    num_new_classes = 10\n","\n","    ###### Classification loss L_ce(x)   (cross-entropy loss)\n","    classification_loss = criterion(outputs, labels)    # automatically divides by |N| = batch size = 128, because reduction='mean'\n","    loss = classification_loss\n","\n","    if old_net is not None:\n","        # From the 2nd set of 10 new classes seen, add to the loss the two\n","        # contributions given by the less-forget constraint and the margin\n","        # ranking loss (for inter-class separation)\n","\n","\n","        ###### Less forget constraint --> L_dis^G(x)   (cosine embedding loss)\n","\n","        ### Compute f(image) and f*(image) for each of the 128 images of this batch and then L2-normalize them\n","        features = net.get_features(images).data    # (128, 64)\n","        features = features / torch.transpose(torch.norm(features, dim=1).unsqueeze(0), 0, 1)   # L2 normalization\n","        old_features = old_net.get_features(images).data    # (128, 64)\n","        old_features = old_features / torch.transpose(torch.norm(old_features, dim=1).unsqueeze(0), 0, 1)   # L2 normalization\n","        #one_hot_labels = torch.eye(100)[labels].to(DEVICE)\n","\n","        ### Compute loss weight lambda\n","        lamda = LAMDA_BASE * np.sqrt(num_old_classes / num_new_classes)\n","\n","        ### Compute the loss\n","        less_forget_constraint = criterion_LF(features, old_features, labels)\n","\n","        loss += lamda * less_forget_constraint\n","\n","\n","        ###### Inter-class separation --> L_mr(x)   (margin ranking loss)\n","\n","        ### Compute N_0, i.e. n. of images of old classes in this minibatch (i.e. exemplars in this minibatch)\n","        set_current_classes = set(current_classes)    # conversion to set (searching for an element in them is faster)\n","        hard_index = np.array([idx for idx,i in enumerate(labels) if i.item() not in set_current_classes])    # at most (128)\n","        N_0 = len(hard_index)\n","\n","        if N_0 > 0:\n","\n","            ### Compute scores before scale, [-1, 1]\n","            outputs_bs = outputs / net.fc.sigma\n","\n","            ### Get ground truth scores\n","            gt_index = torch.eye(100)[labels].ge(0.5).cuda()\n","            gt_scores = outputs_bs.masked_select(gt_index)    # (128); these are the 128 <theta(x),f(x)>\n","            gt_scores = gt_scores[hard_index].view(-1, 1).repeat(1, KK)    # (N_0,KK); these are the N_0 <theta(x),f(x)> where x is an exemplar\n","\n","            ### Get top-KK scores on non-gt classes\n","            non_gt_index = torch.eye(100)[labels].le(0.5).cuda()\n","            non_gt_scores = outputs_bs.masked_select(non_gt_index).reshape((outputs_bs.size(0), outputs.size(1)-1))    # (128,99)\n","            hard_scores = non_gt_scores.topk(KK, dim=1)[0]    # (128,KK)\n","            hard_scores = hard_scores[hard_index]    # (N_0,KK)\n","\n","            ### Compute inter-class separation\n","            interclass_separation = criterion_IS(gt_scores.view(-1, 1), hard_scores.view(-1, 1), torch.ones(N_0*KK).cuda())\n","\n","            loss += interclass_separation\n","\n","    return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73_WXopXU4PZ"},"source":["**Training and testing**"]},{"cell_type":"code","metadata":{"id":"poq9MmpnU7Pg"},"source":["net = net.to(DEVICE)    # this will bring the network to GPU if DEVICE is cuda\n"," \n","cudnn.benchmark         # Calling this optimizes runtime\n"," \n","test_acc_history = []   # this list shall contain 10 values (one for each seen class)\n","test_acc_history_CNN = []\n"," \n","global_step_counter = 0     # Incremented by one every time a training iteration inside an epoch ends\n","task_step_counter = 1       # Incremented by one every time one set of 10 classes is seen\n"," \n","seen_classes_counter = 0    # Incremented by 10 every time one set of 10 classes is seen\n","seen_classes = []           # Is appended with a list of the 10 classes currently seen, each time they are seen\n","\n","old_net = None\n","reserved_classes = []\n"," \n","exemplars_idx = [ [] for _ in range(100) ]     # a list of 100 lists which will contain m int values each; the i-th inner list will contain cifar100_training indices of exemplar images for the i-th class seen\n","\n","for current_classes in classes:     # 10 cycles (over the 10 sets of classes)\n","    # Create a dataloader for the new 10 classes to train on\n","    augm_training_subset_idx = subset_indices(cifar100_training, current_classes, exemplars_idx)   # augm stands for augmented with exemplars of previous classes\n","    augm_training_subset = Subset(cifar100_training, augm_training_subset_idx)\n","    augm_training_dataloader = DataLoader(augm_training_subset, shuffle=True, num_workers=4, batch_size=BATCH_SIZE, drop_last=True)\n","    \n","    # Initialize the optimizer and the scheduler\n","    parameters_to_optimize = net.parameters()\n","    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, STEP_SIZE, gamma=GAMMA)\n"," \n"," \n"," \n","    #################### UPDATE REPRESENTATION ####################\n","    # train on the next set of 10 unseen classes\n"," \n","    net.train(True)\n","    \n","    # 10 previously unseen classes are now being seen\n","    seen_classes_counter += 10\n","    seen_classes += current_classes.tolist()\n"," \n","    epoch_step_counter = 0      # Incremented by one each time an epochs end\n"," \n","    for epoch in range(NUM_EPOCHS):\n","        print(f'Starting epoch {epoch+1}/{NUM_EPOCHS}, LR = {scheduler.get_last_lr()}')\n","        t = time.time()\n"," \n","        \n","        total_training_corrects = 0\n","        running_loss = 0\n"," \n","        for images, labels, indices in augm_training_dataloader:\n"," \n","            # Bring data over the device of choice\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","            optimizer.zero_grad() # Zero-ing the gradients\n"," \n","            # If this is not the first time classes are seen, compute the output logits of the network obtained previously\n","            if task_step_counter >= 2:\n","                old_net = torch.load('cosine_resnet_task' + str(task_step_counter - 1) + '.pt').train(False)\n","                #old_outputs = old_net(images)\n","            \n","            # Forward pass to the network\n","            outputs = net(images)\n"," \n","            # Compute loss\n","            loss = compute_loss(outputs, images, labels, net, current_classes, seen_classes_counter, old_net)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n"," \n","            # Update the running amount of correct predictions\n","            total_training_corrects += torch.sum(preds == labels.data).data.item()\n"," \n","            # Log loss\n","            if epoch_step_counter % LOG_FREQUENCY == 0:\n","                print(f'Step: {epoch_step_counter}, training loss: {loss.item()}')\n"," \n","            # Compute gradients for each layer and update weights\n","            loss.backward()  # backward pass: computes gradients\n","            optimizer.step() # update weights based on accumulated gradients\n"," \n","            # Update the local and global step counter\n","            epoch_step_counter += 1\n","            global_step_counter += 1\n"," \n","        # Compute the accuracy on the current 10 classes (only for reporting purposes)\n","        current_classes_training_accuracy = total_training_corrects / (float(len(augm_training_dataloader)) * BATCH_SIZE)\n","        print(f'------ Epoch {epoch+1}/{NUM_EPOCHS} of the training on the {task_step_counter}° set of classes has ended')\n","        print(f'------ Training accuracy (only on the current 10 classes): {current_classes_training_accuracy}\\n------ Elapsed time for this epoch: {time.time() - t}')\n"," \n","        # Step the scheduler\n","        scheduler.step()\n"," \n"," \n","    # Save the net\n","    torch.save(net, f'cosine_resnet_task{task_step_counter}.pt')\n"," \n"," \n"," \n","    #################### EXEMPLARS MANAGEMENT ####################\n","    # exemplar management part\n"," \n"," \n"," \n","    ###### Reduce exemplar sets of previously seen classes\n"," \n","    m = int(np.ceil(K / float(seen_classes_counter)))   # NB: this can result in a number of exemplars slightly larger than K, but that's how it's done in the original iCaRL code (see main_resnet_tf.py)\n","    for i in range(len(exemplars_idx)):\n","        exemplars_idx[i] = exemplars_idx[i][:m]\n","    \n","    ###### Construct exemplar set for each of the current 10 classes seen\n","\n","    training_subset_idx = subset_indices(cifar100_training, current_classes)   # list of 5000 indices\n","    training_subset = Subset(cifar100_training, training_subset_idx)    # subset of all training images which label is in current_classes\n","\n","    current_classes_means = []  # at the end of the next for loop, this will be (10,64)\n","\n","    for i, cls in enumerate(current_classes): # for each current class\n","\n","        # Retrieve the 500 images of class cls\n","        class_subset_idx = subset_indices(training_subset, [cls])   # absolute indices of the 500 images of class cls\n","        class_subset_images = torch.stack([cifar100_training[j][0] for j in class_subset_idx]).cuda()  # tensor of the 500 images of class cls\n","\n","        # Compute the (exact) class mean (AKA mean feature vector) μ of class cls\n","        features = net.get_features(class_subset_images).cpu().data.numpy()     # (len(class_subset), net.fc.in_features) = (500, 64)-d matrix\n","        features = features / np.array([np.linalg.norm(features, axis=1)]).T    # normalize features (the paper mentions an L2-normalization of features)\n","        class_mean = features.mean(axis=0)  # current class mean of features (64)\n","        class_mean = class_mean / np.linalg.norm(class_mean)    # L2 normalization x / ||x||\n","        current_classes_means.append(class_mean)\n","\n","        # Construct exemplar set for class cls\n","        local_exemplars_idx = []    # relative indices of the 500 images of class cls\n","        for k in range(500):  # m; putting 500 here is a TRICK: all the 500 currently seen images will be used to compute the currently seen classes means, not the m exemplars, so they will be the exact class means\n","            temp = features[local_exemplars_idx]    # features of the k exemplars already found\n","            temp = np.sum(temp, axis=0)             #\n","            temp = features + temp                  # broadcasting! (500, 64)\n","            temp = temp / float(k+1)                # a tiny broadcasting, (500, 64)\n","            temp = class_mean - temp                # broadcasting! (500, 64)\n","            temp = np.linalg.norm(temp, axis=1)     # final norm, (500)\n","            argsort = np.argsort(temp)\n","\n","            for j in argsort:\n","                if j not in local_exemplars_idx:\n","                    exemplars_idx[(seen_classes_counter-10) + i].append(class_subset_idx[j])    # append the absolute index of the exemplar p_k to the exemplar set P_i of the i-th class\n","                    local_exemplars_idx.append(j)\n","                    break\n"," \n"," \n","\n","    #################### TEST PHASE ####################\n","    # NME + CNN classifier\n"," \n","    # Create a dataloader for the test images of all (and only) the classes seen so far\n","    test_subset_idx = subset_indices(cifar100_test, seen_classes)\n","    test_subset = Subset(cifar100_test, test_subset_idx)\n","    test_dataloader = DataLoader(test_subset, shuffle=False, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    net.train(False)    # Set Network to evaluation mode\n","\n","    # Compute the L2-normalized means-of-exemplars for the previously seen (seen_classes_counter-10) classes, and the L2-normalized (exact) class means for the currently seen 10 classes (TRICK)\n","    class_means = compute_means_of_exemplars(net, cifar100_training, exemplars_idx, seen_classes_counter)    # (seen_classes_counter, 64); USE ONLY WITH TRICK: means of exemplars of the previously seen classes and (exact) class means of the currently seen classes\n","    \n","    \n","    all_test_labels = torch.LongTensor([]).to(DEVICE)\n","    all_test_preds = torch.LongTensor([]).to(DEVICE)\n","    all_test_labels_CNN = torch.LongTensor([]).to(DEVICE)\n","    all_test_preds_CNN = torch.LongTensor([]).to(DEVICE)\n","\n","    total_test_corrects = 0\n","    total_test_corrects_CNN = 0\n","\n","    with torch.no_grad():\n","        for images, labels, _ in tqdm(test_dataloader):\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","\n","\n","            ##### CLASSIFICATION WITH NME\n","            # Compute the L2-normalized feature vectors of the images of the current batch of test images\n","            features = net.get_features(images).cpu().data.numpy()    # (128, 64)-d matrix; each row is a ϕ(x)\n","            features = features / np.array([np.linalg.norm(features, axis=1)]).T    # L2 normalization of the ϕ(x)'s\n","            \n","            # Get predictions with the NMoE classifier\n","            preds = []\n","            for feature in features:\n","                pred_idx = np.argmin( np.linalg.norm(feature - class_means, axis=1) )    # relative index of the closest mean of exemplars; this indices a list in the list of lists exemplars_idx\n","                pred = cifar100_training[ exemplars_idx[pred_idx][0] ][1]   # retrieve the label associated with pred_idx; note that all the exemplars which indices are in the same list of exemplars_idx have the same label by definition\n","                preds.append(pred)\n","            preds = torch.LongTensor(preds).to(DEVICE)     # to tensor (needed for the next line of code)\n","\n","            current_batch_corrects = torch.sum(preds == labels.data).data.item()\n","\n","\n","            # Update the running statistics (for plotting purposes)\n","            total_test_corrects += current_batch_corrects\n","\n","            # Store the current batch labels and preds; needed later for plotting the heatmap\n","            all_test_labels = torch.cat((all_test_labels, labels), 0)\n","            all_test_preds = torch.cat((all_test_preds, preds), 0)\n","\n","\n","\n","            ##### CLASSIFICATION WITH CNN\n","            # Forward pass to the network\n","            outputs = net(images)\n","            \n","            # Get predictions\n","            _, preds_CNN = torch.max(outputs.data, 1)\n","            current_batch_corrects_CNN = torch.sum(preds_CNN == labels.data).data.item()\n","\n","            # Update the running amount of correct predictions\n","            total_test_corrects_CNN += current_batch_corrects_CNN\n","\n","            # Store the current batch labels and preds; needed later for plotting the heatmap\n","            all_test_preds_CNN = torch.cat((all_test_preds_CNN, preds_CNN), 0)\n","\n","\n","\n","        test_accuracy = total_test_corrects / float(len(test_subset))\n","        test_acc_history.append(test_accuracy)\n","        test_accuracy_CNN = total_test_corrects_CNN / float(len(test_subset))\n","        test_acc_history_CNN.append(test_accuracy_CNN)\n","    \n","\n","\n","\n","\n","    ### End of training on the 10 currently seen classes\n","\n","\n","    # 10 new classes are to be seen next: update the counter\n","    task_step_counter += 1\n","\n","    print(f'--------------- Training ended on the {int(seen_classes_counter / 10)}° set of classes')\n","    print(f'--------------- Test accuracy (NME): {test_accuracy}')\n","    print(f'--------------- Test accuracy (CNN): {test_accuracy_CNN}')\n","\n","    ###### Reduce exemplar sets of currently seen classes\n","    for i in range( seen_classes_counter-10, seen_classes_counter ):\n","        exemplars_idx[i] = exemplars_idx[i][:m]\n","\n","\n","torch.save(net, 'final_net')  # save the final net on Colab's file system\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sORKQtDcKGNt"},"source":["# Print the 10 test accuracies obtained\n","print(test_acc_history)\n","print(test_acc_history_CNN)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0xjbReTSV2s0"},"source":["**Heatmap Confusion Matrix**"]},{"cell_type":"code","metadata":{"id":"xUD5NbMvnSMo"},"source":["# Show the confusion matrix for the test set as a heatmap\n","show_heatmap_CM(all_test_labels.cpu(), all_test_preds.cpu(), order_of_labels=seen_classes)\n","\n","# x axis: predicted class\n","# y axis: true class"],"execution_count":null,"outputs":[]}]}